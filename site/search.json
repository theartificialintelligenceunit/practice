{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"Practice","text":"<p>These pages continuously outline the data science team’s operating practices vis-à-vis designing, developing, and deploying solutions; ensuring we have the same understanding of the team’s practices.</p> <p>In brief, this is a hub of continuously updated guidelines for</p> <ul> <li>The design, development, and/or deployment of machine learning components that (a) are in-line with software engineering, i.e., programming, best practices, (b) are secure, (c) are available, reliable, maintainable, and resilient, and (d) seamlessly integrate with overarching products.</li> <li>Operating, developing, within secure continuous integration, deployment, and delivery settings.</li> <li>Documenting activities.</li> </ul> <p> </p> <p> </p> <p> </p> <p> </p>","path":["Practice"],"tags":[]},{"location":"sections/cloud-index/","level":1,"title":"Preliminaries","text":"<p>The cloud platform/s will be for secure, efficient, and financially viable operations vis-à-vis:</p> <ul> <li>Developing and/or testing machine learning models.</li> <li>Conducting proof of concept modelling projects.</li> <li>Storing data sets.</li> <li>Investigating the design, development and deployment of solution patterns for machine learning systems/products.</li> </ul> <p> </p> <p> </p> <p> </p> <p> </p>","path":["Cloud Platform","Preliminaries"],"tags":[]},{"location":"sections/cloud-risks/","level":1,"title":"Risks &amp; Mitigation Policies","text":"","path":["Cloud Platform","Risks &amp; Mitigation Policies"],"tags":[]},{"location":"sections/cloud-risks/#data-breach","level":2,"title":"Data Breach","text":"<p>An unauthorised data, or information, access.</p> RiskThreaten cloud systems via corruption of storage systems and their content. MitigationMandatory two-factor authentication via FIDO (Fast Identity Online) Keys. <p></p>","path":["Cloud Platform","Risks &amp; Mitigation Policies"],"tags":[]},{"location":"sections/cloud-risks/#attack-surface","level":2,"title":"Attack Surface","text":"<p>The known and unknown routes via which an entities cloud asset can be infiltrated.</p> RiskThe corruption of cloud assets and the underlying systems, unauthorised access and distribution of  data, reputation damage, financial loss. Endangerment of lives, if personal or sensitive data is present. Mitigation              Data [Classify Data Sets: Open, Sensitive, Personal.]             <ul> <li>Do not store sensitive or personal data within the team's cloud account.</li> <li>Encrypt all data sets; Amazon S3 (Simple Storage Service) encrypts by default.</li> <li>Authorise and withdraw access to data via IAM (Identity &amp; Management) roles.</li><li>Delete redundant data assets.</li> </ul>             Compute Services         <ul> <li>Authorise and withdraw access to compute services via IAM (Identity &amp; Management) roles, and trust policies thereof.</li> <li>Delete redundant compute assets.</li> </ul>             Architectures         <ul><li>Defensive, limited privileges, compute solutions architectures; refer to the architectures pages.</li></ul> <p></p>","path":["Cloud Platform","Risks &amp; Mitigation Policies"],"tags":[]},{"location":"sections/cloud-risks/#malware-infections","level":2,"title":"Malware Infections","text":"<p>Software that enables the unauthorised installer to take control of a system by disrupting it or causing strategic damage.</p> Risk Industrial Espionage <ul> <li>The theft of confidential, sensitive, etc., data or information.</li> <li>The theft of intellectual property, processes, ideas, techniques, etc.</li></ul> Mitigation [Mitigating malware and ransomware attacks]        Cloud       <ul> <li>Enforce multi-factor authentication; the default of GitHub &amp; Amazon Web Services.</li> <li>Encrypt all data sets.</li> <li>Backup data sets; Amazon Web Services Backup for Amazon S3 (Simple Storage Service).</li> <li>Limit access to cloud assets via the inbound rules of security groups.</li> <li>Authorise and withdraw access to assets via IAM (Identity &amp; Management) roles.</li> <li>Restricted data delivery: Programmatic data delivery via data science team members only.</li> <li>Termination of instances immediately after use.</li><li>Prepare an incident contingency.</li></ul>       Client       <ul><li>Interaction with cloud services via virtual private networks.</li></ul> <p></p>","path":["Cloud Platform","Risks &amp; Mitigation Policies"],"tags":[]},{"location":"sections/cloud-risks/#insider-threats","level":2,"title":"Insider Threats","text":"<p>Threats due to employees not adhering to security rules.</p> Risk Infiltration risks, and all the damages thereof. Mitigation At least:       <ul> <li>Always-on virtual private network.</li> <li>Using compute services via infrastructure-as-code templates that always feature           <ul> <li>VPC(Virtual Private Cloud)</li> <li>Subnet</li> <li>Security Groups: For controlling inbound &amp; outbound rules</li></ul> </li> </ul> <p></p>","path":["Cloud Platform","Risks &amp; Mitigation Policies"],"tags":[]},{"location":"sections/cloud-risks/#zero-day-vulnerability","level":2,"title":"Zero Day Vulnerability","text":"<p>An unknown software security flaw; the developers are unaware of its existence.</p> Risk Include:<ul> <li>Zero-day exploits.</li> <li>Zero-day attacks.</li></ul> Mitigation Local<ul> <li>Continuous, automatic, software updates</li> <li>Limited pool of applications.</li> <li>Firewall</li> <li>Network interactions via virtual private network only.</li></ul>         Cloud         <ul> <li>Always use the latest compute services &amp; software.</li></ul> <p></p>","path":["Cloud Platform","Risks &amp; Mitigation Policies"],"tags":[]},{"location":"sections/cloud-risks/#data-loss","level":2,"title":"Data Loss","text":"<p>The loss of data due to a natural disaster, malfunction, etc.</p> RiskThe loss of all data intelligence, e.g., engineered features, developed models, model artefacts, exploratory &amp; trend analysis, etc. Mitigation     At least:     <ul> <li>Backup data sets: Amazon Web Services Backup for Amazon S3 (Simple Storage Service)</li> <li>Programmatic production of all data intelligence/products, via version controlled software programs; hence the wherewithal to reproduce all lost items.  This is a mandatory team practice.</li> </ul> <p></p>","path":["Cloud Platform","Risks &amp; Mitigation Policies"],"tags":[]},{"location":"sections/cloud-risks/#deficient-access-controls","level":2,"title":"Deficient Access Controls","text":"<p>Deficient access controls to cloud, and complementary, assets.</p> Risk      Include:     <ul> <li>An unnecessarily wider attack surface via which threat actors can conduct malicious activities.</li> <li>Financial loss, e.g, by using unaffordable products that were not intended for use by the organisation/team.</li></ul> Mitigation      Amazon Web Services (AWS)     <ul> <li>Programmatic access to Amazon Web Services products via limited privileges roles &amp; trust policies. [Automatic temporary credentials via AWS Command Line Interface Single Sign On]</li> <li>Limited, zero, privileges by default.</li> <li>The continuous development and availability of launch templates, with security settings and limited assets privileges, for launching computing products.</li> <li>The team's cloud leads must use multi-factor authentication to access AWS online.  [Multi-factor authentication by default.]</li></ul>     GitHub     <ul><li>Mandatory multi-factor authentication.</li><li>SSH (Secure Shell) command line interactions.</li></ul> <p></p>","path":["Cloud Platform","Risks &amp; Mitigation Policies"],"tags":[]},{"location":"sections/cloud-risks/#hijacking-cloud","level":2,"title":"Hijacking (Cloud)","text":"<p>The take-over of a cloud account by a threat actor.</p> RiskTheft and disruption, hence reputation and financial losses. MitigationProtect the infiltration route, e.g., interact with cloud services via virtual private networks  only. <p> </p> <p> </p> <p> </p> <p> </p>","path":["Cloud Platform","Risks &amp; Mitigation Policies"],"tags":[]},{"location":"sections/cloud-threats/","level":1,"title":"Threat Actors","text":"","path":["Cloud Platform","Threat Actors"],"tags":[]},{"location":"sections/cloud-threats/#background","level":2,"title":"Background","text":"<p>Each team member must be cognizant of threat actors, i.e., entities or individuals that conduct malicious cyber activities, e.g.,</p> <ul> <li>Exploit vulnerabilities, e.g., zero-day vulnerabilities.</li> <li>Data theft via unauthorised access to computing assets.</li> <li>Intentional disabling or destruction of computing assets, or disruption of services.</li> </ul> <p>The actors have varying motivations. Threat actors will exploit unprotected or insufficiently secured attack surfaces.</p> <p>Potential threat actors are listed below. Presently, the most probable threat actor is an insider. However, as the team (a) grows, (b) starts delivering products &amp; services, and \\(c\\) engages with a wider range of internal &amp; external entities – the threat likelihood per actor increases. [Intellectual property theft, data theft, etc., by external entities will become much more probable.]</p> <ul> <li>Insiders, i.e., employees or contractors.</li> <li>Cyber criminals.</li> <li>Hackers.</li> <li>State actors.</li> </ul> <p></p>","path":["Cloud Platform","Threat Actors"],"tags":[]},{"location":"sections/cloud-threats/#protection","level":2,"title":"Protection","text":"<p>The Cyber Security Body of Knowledge is a helpful cyber security reference text.  Practically, the team will be guided by the SOPHOS protection proposals, e.g.,</p> Risk AssessmentThe risks &amp; mitigation policies page addresses this. Security Policies &amp; ProceduresThe risks &amp; mitigation policies page addresses this. Enforce Access ControlZero privilege approach. Initially, each team member will have a zero privileges account, i.e., Amazon Web Services products will be inaccessible. Privileges will be set, and withdrawn, via IAM (Identity &amp; Access Management) roles, and trust policies thereof. Mandatory multi-factor authentication for cloud tools, e.g., Amazon Web Services, GitHub, etc. Automatic Code Scanning, Code Vulnerability Alerts GitHub DEPENDEABOTS, GitHub CodeQL <p> </p> <p> </p>","path":["Cloud Platform","Threat Actors"],"tags":[]},{"location":"sections/integration-cloud/","level":1,"title":"Amazon Web Services","text":"<p>After connecting to an Amazon Web Services (AWS) account, directly or via an identity service, the AWS access portal screen appears.  The details therein are critical to setting up programmatic access to AWS directly.</p> <p></p>","path":["Continuous Integration, etc.","Amazon Web Services"],"tags":[]},{"location":"sections/integration-cloud/#programmatic-access","level":2,"title":"Programmatic Access","text":"","path":["Continuous Integration, etc.","Amazon Web Services"],"tags":[]},{"location":"sections/integration-cloud/#install-aws-cli","level":3,"title":"Install AWS CLI","text":"<p>Foremost, install AWS CLI (Command Line Interface).  If using a machine that has Windows Subsystem for Linux, </p> <ul> <li>Install aws cli within Windows, and relevant Linux Kernels.</li> <li>Subsequently, work through the steps below within Windows; the outcomes propagate to Linux Kernels.</li> </ul>","path":["Continuous Integration, etc.","Amazon Web Services"],"tags":[]},{"location":"sections/integration-cloud/#basic-configuration","level":3,"title":"Basic Configuration","text":"<p>Configuration is via <code>aws configure</code> of aws cli.  The key values of the <code>aws configure</code> parameters are set via the directives below.  Use this image, and the notes below, to determine the parameter values, i.e., the values in brackets. </p> Bash<pre><code>aws configure set sso_session {sso.session.string} --profile default\naws configure set sso_account_id {account id} --profile default\naws configure set sso_role_name {aws sso role name} --profile default\naws configure set region {region} --profile default\naws configure set output {output.string} --profile default\n</code></pre> <p>Note, the value of the sso_session parameter is user dependent.  It is a string that names a session, e.g., to name a session alpha</p> Bash<pre><code>aws configure set sso_session alpha --profile default\n</code></pre> <p>There are a few output value options, e.g.,  </p> Bash<pre><code>aws configure set output json --profile default\n</code></pre> <p>or </p> Bash<pre><code>aws configure set output yaml --profile default\n</code></pre> <p></p>","path":["Continuous Integration, etc.","Amazon Web Services"],"tags":[]},{"location":"sections/integration-cloud/#single-sign-on-sso-configuration","level":3,"title":"Single Sign On (SSO) Configuration","text":"<p>The image above has a link named Access keys; each account within a portal page will have its own Access keys link.  Within your AWS access portal, click on the Access keys link of the account of interest.  A pop-up, similar to this.  Hence, to configure/set single sign on settings, type</p> Bash<pre><code>aws configure sso\n</code></pre> <p>Subsequently, and aided by the image above, answer the questions below</p> Text Only<pre><code>SSO session name [sso.session.string]: {sso.session.string}\nSSO start URL [None]: {url}\nSSO region [None]: {region}\nSSO registration scopes [sso:account:access]: sso:account:access\n</code></pre> <p></p>","path":["Continuous Integration, etc.","Amazon Web Services"],"tags":[]},{"location":"sections/integration-cloud/#hence-programmatic-single-sign-on-sso","level":3,"title":"Hence, Programmatic Single Sign On (SSO)","text":"Bash<pre><code>aws sso login --profile {profile.name}\n</code></pre>","path":["Continuous Integration, etc.","Amazon Web Services"],"tags":[]},{"location":"sections/integration-cloud/#testing-programmatic-access","level":2,"title":"Testing Programmatic Access","text":"<p>Via command line, e.g., by listing Amazon S3 objects:</p> Bash<pre><code>aws s3 ls\n</code></pre> <p>Or, by listing the container images of an Amazon ECR (Elastic Container Registry) repository of an account.</p> Bash<pre><code>aws ecr list-images --registry-id {account.identifer} \n  --repository-name {repository.name}\n</code></pre> <p> </p>","path":["Continuous Integration, etc.","Amazon Web Services"],"tags":[]},{"location":"sections/integration-cloud/#references","level":2,"title":"References","text":"<ul> <li>AWS CLI with IAM Identity Centre</li> <li>IAM (Identity &amp; Access Management) Roles</li> <li>Amazon Web Services Managed Policies</li> <li>Changing or setting a region</li> </ul>","path":["Continuous Integration, etc.","Amazon Web Services"],"tags":[]},{"location":"sections/integration-github/","level":1,"title":"GitHub &amp; Assets Delivery","text":"<p>Automatically delivering assets to Amazon Web Services (AWS) via GitHub, hence enabling continuous integration, delivery, and deployments.</p>","path":["Continuous Integration, etc.","GitHub &amp; Assets Delivery"],"tags":[]},{"location":"sections/integration-github/#identity-provider","level":2,"title":"Identity Provider","text":"<p>Foremost, add the requisite identity provider</p> <ul> <li>Adding the GitHub OIDC (Open Identifier Connect) identity provider to Amazon Web Services</li> </ul>","path":["Continuous Integration, etc.","GitHub &amp; Assets Delivery"],"tags":[]},{"location":"sections/integration-github/#identity-asset-management-role","level":2,"title":"Identity &amp; Asset Management Role","text":"<p>Subsequently, create an AWS IAM (Identity &amp; Asset Management) role for GitHub OIDC connections.</p> <ul> <li>create</li> <li>ascertain configuration</li> </ul> <p>During the policy step, select a policy, or policies, in relation to the purpose of the role being created, e.g., for delivering images to Amazon ECR (Elastic Container Registry) (REF: Point 8)</p> <p>... IAM includes a list of the AWS managed and customer managed policies in your account. Select the policy to use for the permissions policy ...</p> <p> </p> <p> </p> <p> </p> <p> </p>","path":["Continuous Integration, etc.","GitHub &amp; Assets Delivery"],"tags":[]},{"location":"sections/integration-ic/","level":1,"title":"Images &amp; Containers","text":"<p>Designing &amp; developing within containers.</p>","path":["Continuous Integration, etc.","Images &amp; Containers"],"tags":[]},{"location":"sections/integration-ic/#for-development","level":2,"title":"For Development","text":"<p>For Python projects, create:</p> <ul> <li>requirements.txt</li> <li>Dockerfile</li> <li>devcontainer.json: optional, for GitHub CodeSpaces</li> </ul> <p>Within the <code>.devcontainer/</code> directory, which must be within the project's parent directory; example.  Always ascertain that the <code>requirements.txt</code> file lists the packages/libraries required for development.  Next, build the image:</p> Bash<pre><code>docker build . --file .devcontainer/Dockerfile --tag {tag.name}\n</code></pre> <p>Subsequently, run an instance of the image for development purposes, e.g.,</p> Bash<pre><code>docker run --rm -i -t -p 127.0.0.1:10000:8888 -w /app\n  --mount type=bind,src=\"$(pwd)\",target=/app {tag.name}\n</code></pre> <p>or</p> Bash<pre><code>docker run --rm -i -t -p 127.0.0.1:10000:8888 -w /app\n  --mount type=bind,src=\"$(pwd)\",target=/app -v ~/.aws:/root/.aws {tag.name}\n</code></pre> <p>wherein</p> <ul> <li>--rm: automatically remove container</li> <li>-i: interact</li> <li>-t: tag</li> <li>-p: publish a container's port to a host port</li> <li>--mount type=bind: a bind mount</li> <li>-v: volume</li> </ul> <p>and <code>-p 10000:8888</code> maps the host port <code>10000</code> to container port <code>8888</code>.  Note, the container's working environment, i.e., -w, must be inline with this project's top directory.  The second option is important for interactions with Amazon Web Services.</p> <p>Get the name of the running instance of {tag.name} via:</p> Bash<pre><code>docker ps --all\n</code></pre> <p>Next, attach the running IDE (integrated development environment) application to a running container.  If IntelliJ IDEA, connect to a Docker daemon via<sup>1</sup></p> <ul> <li>Settings → Build, Execution, Deployment → Docker → WSL: {operating.system}</li> <li>View → Tool Window Services Within the Containers section connect to the running instance of interest, or ascertain connection to the running instance of interest.</li> </ul>","path":["Continuous Integration, etc.","Images &amp; Containers"],"tags":[]},{"location":"sections/integration-ic/#for-deployment","level":2,"title":"For Deployment","text":"<p>Never deploy root containers; study this production Dockerfile, which blocks access to <code>root</code> by creating a standard user; cf. the development Dockerfile.</p> <p> </p> <p> </p> <p> </p> <ol> <li> <p>Visual Studio Code as its container attachment instructions; study Attach Container. ↩</p> </li> </ol>","path":["Continuous Integration, etc.","Images &amp; Containers"],"tags":[]},{"location":"sections/integration-index/","level":1,"title":"Preliminaries","text":"<p>The integration pages continuously outline the continuous integration, delivery, deployment patterns of the team vis-à-vis GitHub &amp; Amazon Web Services.<sup>1</sup></p> <p> </p> <p> </p> <p> </p> <p> </p> <ol> <li> <p>An Introduction to Continuous Integration, Delivery, and Deployment ↩</p> </li> </ol>","path":["Continuous Integration, etc.","Preliminaries"],"tags":[]},{"location":"sections/integration-resources/","level":1,"title":"Resources","text":"<p>For quick-start remote-development-image-containers, try the templates herein.</p> <p> </p> <p> </p> <p> </p> <p> </p>","path":["Continuous Integration, etc.","Resources"],"tags":[]},{"location":"sections/languages-etc/","level":1,"title":"Languages, etc.","text":"","path":["Languages &<br>Frameworks","Languages, etc."],"tags":[]},{"location":"sections/languages-etc/#python","level":2,"title":"Python","text":"","path":["Languages &<br>Frameworks","Languages, etc."],"tags":[]},{"location":"sections/languages-etc/#fundamentals","level":3,"title":"Fundamentals","text":"<p>Please use the PEP (Python Enhancement Proposal) 8 Style Guide for Python.  Always refer to the naming conventions guide, for example:</p> <p></p> ObjectNote Type Variable NameAlways pascal case, e.g., HyperParameter. Class NameAlways pascal case. Variable NameA lower case or snake case string, e.g., length, `number_of_cities` Use two leading underscores for private variables. ConstantsThe PEP pages note that constants ... are usually defined on a  module level and written in all capital letters with underscores separating words. Examples include MAX_OVERFLOW and TOTAL. <p></p>","path":["Languages &<br>Frameworks","Languages, etc."],"tags":[]},{"location":"sections/languages-etc/#importing-modules","level":3,"title":"Importing Modules","text":"<p>Abide by the module importing advice of the HitchHiker's Guide to Python, it is an excellent guide to Python software development best practices; beware of the readability advice.  Hence, please use the import format <code>import math</code>, and use a method of the module via the pattern</p> Python<pre><code>import math\n\nmath.cos(...)\n</code></pre> <p>not</p> <p> <code>from math import cos</code></p> <p> <code>from math import *</code></p> <p></p>","path":["Languages &<br>Frameworks","Languages, etc."],"tags":[]},{"location":"sections/languages-etc/#scala","level":2,"title":"Scala","text":"<p>The Scala Style Guide will be the team's style reference. Take note of the naming conventions.  The names of classes, objects, methods, etc., are either pascal case, also known as upper camel case, camel case, or lower case.  Names do not include underscores.</p> <p></p> ObjectNote Classes/Traits Pascal Case Objects Pascal Case Packages In line with Java's packages naming conventions: Baeldung, javapoint Constants Pascal Case <p></p>","path":["Languages &<br>Frameworks","Languages, etc."],"tags":[]},{"location":"sections/languages-etc/#shell","level":2,"title":"Shell","text":"<p>Refer to Google's Shell Style Guide</p> <p> </p> <p> </p> <p> </p> <p> </p>","path":["Languages &<br>Frameworks","Languages, etc."],"tags":[]},{"location":"sections/languages-index/","level":1,"title":"Preliminaries","text":"Remote Development For a quick start to remote development via container, try the templates herein. <p>Important:</p> <ul> <li>Always use the style guides that the languages pages reference.</li> <li>The structure of a package must always be in line with the underlying language's project structure.</li> <li>Deploy all machine learning packages via container images.</li> <li>The GitHub Actions YAML of a package repository must include           <ul> <li>Automated code analysis.</li> <li>Container image building and registration features.</li> </ul> </li> <li>Beware of file storage practices.</li> </ul> <p> </p> <p> </p>","path":["Languages &<br>Frameworks","Preliminaries"],"tags":[]},{"location":"sections/machines-gpu/","level":1,"title":"Graphics Processing Unit, etc.","text":"<p>Before proceeding, install Docker Desktop: ref. Fundamental Software: Windows.</p>","path":["Machines","Graphics Processing Unit, etc."],"tags":[]},{"location":"sections/machines-gpu/#key-windows-settings","level":2,"title":"Key Windows Settings","text":"<p>The references herein outline the fundamental NVIDIA installations required within Windows 11 that ensure the ability to run CUDA dependent programs/containers within Windows 11 or a WSL (Windows Subsystem for Linux) kernel. </p>","path":["Machines","Graphics Processing Unit, etc."],"tags":[]},{"location":"sections/machines-gpu/#nvidia-driver","level":3,"title":"NVIDIA Driver","text":"<p>Beware of the mappings between CUDA Toolkit Version &amp; CUDA Driver Version.  Before installing unloading an NVIDIA driver, determine the machine's CUDA GPU (Graphics Processing Unit) type.  Within the Windows desktop</p> <ul> <li>Right Click</li> <li>SELECT Show more options</li> <li>SELECT NVIDIA Control Panel</li> </ul> <p>The NVIDIA Control Panel's landing page will display the name of the machine's Graphics Processing Unit, e.g., NVIDIA RTX 2000 Ada Generation Laptop GPU.  Subsequently, download the appropriate NVIDIA Driver; in relation to the above example</p> <ul> <li>Product Category: NVIDIA RTX/Quadro</li> <li>Product Series: NVIDIA RTX Series (Notebooks)</li> <li>Product: NVIDIA RTX 2000 Ada Generation Laptop GPU</li> <li>Operating System [If uncertain, check Settings &amp;rarr System &amp;rarr About]</li> </ul> <p>Install.</p> During Installation <p> <ul> <li>AGREE AND CONTINUE</li> <li>Custom (Advanced)</li> <li>Perform clean installation         <ul> <li>HD Audio Driver</li> <li>RTX Desktop Manager</li> <li>Graphics Driver</li> <li>USB-C Driver</li> </ul> </li> </ul> </p> <p>After installation NVIDIA will request a machine restart: restart.</p>","path":["Machines","Graphics Processing Unit, etc."],"tags":[]},{"location":"sections/machines-gpu/#nvidia-cuda-toolkit","level":3,"title":"NVIDIA CUDA Toolkit","text":"<p>Install NVIDIA CUDA Toolkit; release notes.  Installation Steps:</p> <ul> <li>NVIDIA software licence agreement: AGREE AND CONTINUE</li> <li>Custom installation options: deselect visual studio integration</li> <li>Leave the default installation location → C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v{version.number}</li> </ul>","path":["Machines","Graphics Processing Unit, etc."],"tags":[]},{"location":"sections/machines-gpu/#cudnn","level":3,"title":"cuDNN","text":"<p>Skip: Install cuDNN within development containers.</p> <p> </p>","path":["Machines","Graphics Processing Unit, etc."],"tags":[]},{"location":"sections/machines-gpu/#within-linux-kernels","level":2,"title":"Within Linux Kernels","text":"","path":["Machines","Graphics Processing Unit, etc."],"tags":[]},{"location":"sections/machines-gpu/#nvidia-container-toolkit","level":3,"title":"NVIDIA Container Toolkit","text":"","path":["Machines","Graphics Processing Unit, etc."],"tags":[]},{"location":"sections/machines-gpu/#installing","level":4,"title":"Installing","text":"<p>A key tool for building and running GPU accelerated containers is the NVIDIA Container Toolkit.  This section outlines the installation of the toolkit via APT (Advanced Package Tool); NVIDIA outlines a few options.  Set-up, configure, the production repository via commands:</p> Bash<pre><code>curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | \n  sudo gpg --dearmour -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg\n</code></pre> <p>and</p> Bash<pre><code>curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \n    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \n    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n</code></pre> <p>Next, update the repository's packages list:</p> Bash<pre><code>sudo apt update\n</code></pre> <p>Finally, install the NVIDIA Container Toolkit packages:</p> Bash<pre><code>sudo apt install -y nvidia-container-toolkit\n</code></pre> <p></p>","path":["Machines","Graphics Processing Unit, etc."],"tags":[]},{"location":"sections/machines-gpu/#configuring","level":4,"title":"Configuring","text":"<p>Initially, configure the container runtime for docker; NVIDIA's pages detail extra component dependent configurations.  </p> Bash<pre><code>sudo nvidia-ctk runtime configure --runtime=docker\n</code></pre> <p>Subsequently, restart docker via docker desktop.</p> <p></p> <p> </p>","path":["Machines","Graphics Processing Unit, etc."],"tags":[]},{"location":"sections/machines-gpu/#testing","level":4,"title":"Testing","text":"<p>Foremost, determine the machines CUDACompute Unified Device Architecture version, i.e.,  {major}.{minor}.{build}, via</p> Bash<pre><code>nvidia-smi\n</code></pre> <p>and Ubuntu version, i.e., {major}.{minor}, via</p> Bash<pre><code>cat /etc/os-release\n</code></pre> <p>Subsequently, use</p> Bash<pre><code>docker run --rm --gpus all nvidia/cuda:{cuda_version}-base-ubuntu{ubuntu_version} nvidia-smi\n</code></pre> <p>to create and run a CUDA test command, e.g.,</p> Bash<pre><code>docker run --rm --gpus all nvidia/cuda:12.5.1-base-ubuntu22.04 nvidia-smi\n</code></pre> <p>The CUDACompute Unified Device Architecture version must match the machines CUDA version.  Sometimes the required CUDA &amp; Ubuntu versions combination might not exist, alternative &amp; close Ubuntu versions sometimes suffice.</p> <p></p>","path":["Machines","Graphics Processing Unit, etc."],"tags":[]},{"location":"sections/machines-gpu/#downgrading","level":4,"title":"Downgrading","text":"Help Notes <p>The components matrix of an NVIDIA CUDA Toolkit Release outlines the components of the toolkit release, and the version of each component.   [Archive]</p> <p>Sometimes it might be necessary to downgrade NVIDIA CUDA Toolkit after upgrading.  This example illustrates downloading from 12.5 to 12.2.</p> <ul> <li>Uninstall 12.5 / All NVIDIA Components: Restart the machine as many times as necessary.</li> <li>Downgrade to 12.2; download.</li> <li>Install<ul><li>Opt for custom installation: deselect visual studio integration.</li></ul></li> <li>Check environment variable paths</li> <li>Re-start</li> <li>Re-configure linux container toolkit settings: Configuring Docker</li> <li>Re-start docker</li> </ul> <p> </p> <p> </p> <p> </p> <p> </p>","path":["Machines","Graphics Processing Unit, etc."],"tags":[]},{"location":"sections/machines-index/","level":1,"title":"Preliminaries","text":"Info <p>At present, each colleague's machine is a HP ZBook Fury 16 G10 Mobile Workstation; selected from the organisation's HP brochure, and purchased via digital purchasing.  Specification Excerpt: NVIDIA RTX 2000 Ada 8GB Graphics, Intel Core i7-13700HX Processor, 32GB (2 x 16GB) DDR5 4800 SO-DIMM Memory, 2TB PCIe-4x4 2280 NVMe SED OPAL 2.0 TLC SSD. etc.</p> <p>All the organisation's computer usage rules apply; including the Universal Serial Bus (USB) sticks ban.</p>","path":["Machines","Preliminaries"],"tags":[]},{"location":"sections/machines-index/#initial-set-up","level":2,"title":"Initial Set-up","text":"<p>Switch-on the new machine and proceed as guided, but</p> <ul> <li>Do not select Microsoft Account.  Instead, select the School/Business option, thereafter select other domains option.</li> <li>Install and set up the security software.</li> <li>Hard Drive Partitioning: Consider partitioning the C drive into two drives; such that the second drive is for development purposes.</li> </ul>","path":["Machines","Preliminaries"],"tags":[]},{"location":"sections/machines-index/#additionally","level":2,"title":"Additionally","text":"<p>Install</p> <ul> <li>firefox</li> <li>opera</li> <li>KeePassXC</li> </ul> <p>within Windows.  Ensure that the privacy &amp; security settings of the browsers are strict; additionally, set the default search engine to duckduckgo.</p> <p> </p> <p> </p> <p> </p> <p> </p>","path":["Machines","Preliminaries"],"tags":[]},{"location":"sections/machines-linux/","level":1,"title":"Fundamental Software: Linux","text":"<p>Apriori</p> Bash<pre><code>sudo apt update\nsudo apt upgrade\n</code></pre> <p>Additionally, inspect the GNU Privacy Guard (GPG) keys via:</p> Bash<pre><code>gpg --list-keys\ngpg --list-secret-keys\n</code></pre> <p></p>","path":["Machines","Fundamental Software: Linux"],"tags":[]},{"location":"sections/machines-linux/#wget","level":2,"title":"WGET","text":"<p>Check if the wget utility exists:</p> Bash<pre><code>wget --version\n</code></pre> <p>If <code>wget</code> does not exist, install it; additionally, install <code>ca-certificates</code>:</p> Bash<pre><code>sudo apt install wget ca-certificates\n</code></pre> <p><code>ca-certificates</code> allows applications that are secure sockets layer (SSL) dependent to verify the authenticity of SSL connections; SSL is a deprecated tool.</p> <p></p>","path":["Machines","Fundamental Software: Linux"],"tags":[]},{"location":"sections/machines-linux/#java","level":2,"title":"JAVA","text":"","path":["Machines","Fundamental Software: Linux"],"tags":[]},{"location":"sections/machines-linux/#installing-java","level":3,"title":"Installing Java","text":"<p>For more details study this tutorial by DigitalOcean.  Example, pre Ubuntu 24.04 era:</p> Bash<pre><code># jdk &amp; jre\nsudo apt install openjdk-19-jdk-headless\njava --version\njavac --version\n</code></pre> <p>For Ubuntu 24.04 LTS (Long Term Supported)</p> Bash<pre><code># jdk &amp; jre\nsudo apt install default-jdk\njava --version\njavac --version\n</code></pre>","path":["Machines","Fundamental Software: Linux"],"tags":[]},{"location":"sections/machines-linux/#java-environment-variables","level":3,"title":"Java Environment Variables","text":"<p>The environment variable of interest is the <code>JAVA_HOME</code> variable, which depends on the installation directory string, i.e.,</p> <p>Bash<pre><code>sudo update-alternatives --config java\n</code></pre> or</p> Bash<pre><code>readlink -f `which java`\n</code></pre> <p>The <code>JAVA_HOME</code> environment variable is defined as</p> Bash<pre><code>readlink -f `which java` | sed \"s:/bin/java::\"\n</code></pre> <p>i.e., the <code>/bin/java</code> suffix of the penultimate command's output is excluded/removed. If the resulting string is <code>/usr/lib/jvm/java-19-openjdk-amd64</code>, then</p> Bash<pre><code>export JAVA_HOME=/usr/lib/jvm/java-19-openjdk-amd64\n</code></pre> <p>Or rather, edit <code>/etc/environment</code> by appending the definition of <code>JAVA_HOME</code> at the end of the file.  An edit mode option is</p> Bash<pre><code>sudo vi /etc/environment\n</code></pre> <p>Subsequently, append</p> Bash<pre><code>JAVA_HOME=/usr/lib/jvm/java-19-openjdk-amd64\n</code></pre> `vi` Help Notes   The directive    <ul> <li>`i` starts the edit mode</li> <li>`ESC` exits the mode</li> <li>`:wq` saves</li> </ul>    More `vi` directives herein.  <p></p>","path":["Machines","Fundamental Software: Linux"],"tags":[]},{"location":"sections/machines-linux/#git","level":2,"title":"GIT","text":"<p>Update <code>git</code> via the <code>git-core/ppa</code><sup>1</sup>.  Pre Ubuntu 24.04 era:</p> Bash<pre><code>sudo add-apt-repository ppa:git-core/ppa\nsudo apt update\nsudo apt install git-all\n</code></pre> <p>Case Ubuntu 24.04 LTS (Long Term Supported)</p> Bash<pre><code>sudo add-apt-repository ppa:git-core/ppa\nsudo apt update\nsudo apt upgrade\n</code></pre> <p>Subsequently, set up &amp; configure <code>git</code> ...</p> Bash<pre><code>git config --global user.name \"\"\n\n# Navigate to Settings -&gt; Emails ... within the *Primary email address* section \n# you will find a ...@users.noreply.github.com address that can be used \n# for Git operations.  Additionally, consider enabling - Keep my \n# email addresses private \ngit config --global user.email \"...@users.noreply.github.com\"\n\ngit config --global core.editor \"vim --nofork\"\ngit config --global init.defaultBranch master\n</code></pre> <p></p> <p>Next, SSH key</p> Bash<pre><code>ssh-keygen -t ed25519 -C \"...@users.noreply.github.com\"\n$ Enter file in which to save the key ... [Default ↦ ENTER.]\n</code></pre> <p>Beware, a key re-write might be requested if a key file already exists.  The command</p> Bash<pre><code>cat ~/.ssh/id_ed25519.pub\n</code></pre> <p>prints the text for setting-up SSH key pair within a version control service.  For instances whereby multiple accounts have to be managed per git client study GitHub Multiple Accounts.</p> <p></p>","path":["Machines","Fundamental Software: Linux"],"tags":[]},{"location":"sections/machines-linux/#conda-optional","level":2,"title":"CONDA [Optional]","text":"<p>This is for readers that sometimes need to develop outwith a container, i.e., within a virtual environment of the host machine instead.  Installation is via <code>miniconda</code>.  Foremost, check the python version</p> Bash<pre><code>python --version\n</code></pre>","path":["Machines","Fundamental Software: Linux"],"tags":[]},{"location":"sections/machines-linux/#the-installer","level":3,"title":"The Installer","text":"<p>Subsequently, <code>get</code> the installer relative to the system's python version, e.g.,</p> Bash<pre><code># if python 3.10.*\nsudo wget -P Downloads \n  https://repo.anaconda.com/miniconda/Miniconda3-py310_24.4.0-0-Linux-x86_64.sh\ncd Downloads\nsudo chmod +x Miniconda3-py310_24.4.0-0-Linux-x86_64.sh\n</code></pre> <p></p>","path":["Machines","Fundamental Software: Linux"],"tags":[]},{"location":"sections/machines-linux/#install","level":3,"title":"Install","text":"<p>Install in the specified directory</p> Bash<pre><code># Include &lt;-b&gt; for automatic acceptance of the terms &amp; conditions\nsudo bash Miniconda3-py310_24.4.0-0-Linux-x86_64.sh -p /opt/miniconda3\n\n$ Do you wish the installer to initialize Miniconda3 by running conda init?\n&gt;&gt;&gt; no\n</code></pre> <p></p>","path":["Machines","Fundamental Software: Linux"],"tags":[]},{"location":"sections/machines-linux/#set-the-path-variable","level":3,"title":"Set the Path Variable","text":"<p>Open <code>/etc/profile</code>, i.e.,</p> Bash<pre><code>sudo vi profile\n</code></pre> <p>and append</p> Bash<pre><code>if ! [[ $PATH =~ \"/opt/miniconda3/bin\" ]]; then\n    PATH=\"/opt/miniconda3/bin:$PATH\"\nfi\n</code></pre> <p>The command <code>i</code> starts the edit mode, <code>ESC</code> exits the mode, and <code>:wq</code> saves; <code>vi</code> commands.  Exit the terminal.</p> <p></p>","path":["Machines","Fundamental Software: Linux"],"tags":[]},{"location":"sections/machines-linux/#set-up","level":3,"title":"Set-up","text":"<p>Next, within a new terminal</p> Bash<pre><code>conda init bash\nconda config --set auto_activate_base false\nsudo chown -R $USER:$USER /opt/miniconda3\n</code></pre> <p></p>","path":["Machines","Fundamental Software: Linux"],"tags":[]},{"location":"sections/machines-linux/#upkeep","level":3,"title":"Upkeep","text":"<p>Update conda via</p> Bash<pre><code>conda update -n base -c anaconda conda\n</code></pre> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <ol> <li> <p>Personal Package Archive ↩</p> </li> </ol>","path":["Machines","Fundamental Software: Linux"],"tags":[]},{"location":"sections/machines-windows/","level":1,"title":"Fundamental Software: Windows","text":"","path":["Machines","Fundamental Software: Windows"],"tags":[]},{"location":"sections/machines-windows/#core","level":2,"title":"CORE","text":"","path":["Machines","Fundamental Software: Windows"],"tags":[]},{"location":"sections/machines-windows/#basic-tools","level":3,"title":"Basic Tools","text":"<p>Foremost, install</p> <ul> <li>Notepad++ / Notepad++</li> <li>Java: [JDK &amp; JRE]</li> </ul>","path":["Machines","Fundamental Software: Windows"],"tags":[]},{"location":"sections/machines-windows/#open-office","level":3,"title":"Open Office","text":"<p>Unload the core executable &amp; language pack of OpenOffice.</p>","path":["Machines","Fundamental Software: Windows"],"tags":[]},{"location":"sections/machines-windows/#git","level":3,"title":"Git","text":"<p>Unload the executable at git-scm, subsequently install.</p> Install GIT <p>Select Destination Location</p> <p>This installation directory.</p> <p>Select Components</p> <p>Deselect</p> <p><ul> <li>Additional icons On the Desktop</li> <li>Git LFS (Large File Support)</li> <li>Add a Git Bash Profile to Windows Terminal</li> </ul></p> <p>Select Start Menu Folder</p> <p>Deselect</p> <p><ul> <li>Don't create a Start Menu folder</li> </ul></p> <p>Choosing the default editor used by Git</p> <p>Select</p> <p><ul> <li>Use Notepad++ as Git's default editor</li> </ul></p> <p>Adjusting the name of the initial branch in new repositories</p> <p>Select</p> <p><ul> <li>Override the default branch name for new repositories [master]</li> </ul></p> <p>Adjusting your PATH environment</p> <p>Select</p> <p><ul> <li>Git from the command line and also from 3rd-party software</li> </ul></p> <p>Choosing the SSH executable</p> <p>Select</p> <p><ul> <li>Use bundled OpenSSH</li> </ul></p> <p>Choosing HTTPS Transport Backend</p> <p>Select</p> <p><ul> <li>Use the OpenSSL library</li> </ul></p> <p>Configuring the line ending conversions</p> <p>Select</p> <p><ul> <li>Checkout Windows-style, commit Unix-style line endings</li> </ul></p> <p>Configuring the terminal emulator to use with Git Bash</p> <p>Select</p> <p><ul> <li>Use MinTTY (the default terminal of MSYS2)</li> </ul></p> <p>Choose the default behaviour of <code>git pull</code></p> <p>Select</p> <p><ul> <li>Fast-forward or merge</li> </ul></p> <p>Choose a credential helper</p> <p>Select</p> <p><ul> <li>None</li> </ul></p> <p>Configuring extra option</p> <p>Select</p> <p><ul> <li>Enable file system caching</li> </ul></p> <p>Configuring experimental options</p> <p><ul> <li>Deselect all</li> </ul></p> <p></p>","path":["Machines","Fundamental Software: Windows"],"tags":[]},{"location":"sections/machines-windows/#installations-that-propagate-to-wsl-kernels","level":2,"title":"INSTALLATIONS THAT PROPAGATE TO WSL KERNELS","text":"","path":["Machines","Fundamental Software: Windows"],"tags":[]},{"location":"sections/machines-windows/#docker-desktop","level":3,"title":"Docker Desktop","text":"<p>Unload Docker Desktop, subsequently install.  During installation</p> <ul> <li> Use WSL-2 instead of Hyper-V  [Select]</li> <li> Add shortcut to desktop [Deselect]</li> </ul> <p></p>","path":["Machines","Fundamental Software: Windows"],"tags":[]},{"location":"sections/machines-windows/#intellij-idea-ultimate","level":3,"title":"IntelliJ IDEA Ultimate","text":"<p>Unload IntelliJ IDEA Ultimate, subsequently install.  During the product's initial launch, a licence screen appears.  Activate your licence via one of the presented methods, e.g., via an Activation Code.</p> <p></p>","path":["Machines","Fundamental Software: Windows"],"tags":[]},{"location":"sections/machines-windows/#vs-code","level":3,"title":"VS Code","text":"<p>Study the Visual Studio CODE installation notes.  Whilst installing VS Code</p> <ul> <li>Select Destination Location (This is about the installation directory)</li> <li>Select Start Menu Folder (Leave default text)</li> <li>Select Additional Tasks (Ensure `Add to PATH (requires shell restart)` is selected.  Deselect everything else.)</li> </ul> <p>Subsequently, and after launching VS Code, install the Remote Development extension pack via the extension button.</p> <p> </p> <p> </p> <p> </p> <p> </p>","path":["Machines","Fundamental Software: Windows"],"tags":[]},{"location":"sections/machines-wsl/","level":1,"title":"Linux &amp; Windows Subsystem for Linux (WSL)","text":"<p>Using a Linux Kernel requires (a) activating WSL, and (b) installing a Linux distribution.  The auto-script approach sometimes fails.  This section outlines the semi-manual approach.  For reference purposes:</p> <ul> <li>Auto</li> <li>Manual</li> </ul> <p></p>","path":["Machines","Linux &amp; Windows Subsystem for Linux (WSL)"],"tags":[]},{"location":"sections/machines-wsl/#activate-windows-subsystem-for-linux","level":2,"title":"Activate Windows Subsystem for Linux","text":"<p>The activation steps are</p> <p>Control Panel \\(\\rightarrow\\) Uninstall a program \\(\\rightarrow\\) Turn Windows features on or off \\(\\rightarrow\\) Windows Subsystem for Linux.</p> <p>Subsequently, re-start the machine.</p> <p></p>","path":["Machines","Linux &amp; Windows Subsystem for Linux (WSL)"],"tags":[]},{"location":"sections/machines-wsl/#enable-the-virtual-machine-feature-via-powershell-administrator-mode","level":2,"title":"Enable the virtual machine feature via PowerShell; administrator mode.","text":"<p>For details visit enable virtual machine feature.</p> PowerShell<pre><code>  dism.exe /online /enable-feature \n    /featurename:VirtualMachinePlatform /all /norestart\n</code></pre> <p></p>","path":["Machines","Linux &amp; Windows Subsystem for Linux (WSL)"],"tags":[]},{"location":"sections/machines-wsl/#linux-kernel-update-package","level":2,"title":"Linux Kernel Update Package","text":"<p>Download and install the package.</p> <p></p>","path":["Machines","Linux &amp; Windows Subsystem for Linux (WSL)"],"tags":[]},{"location":"sections/machines-wsl/#download-install-a-linux-distribution","level":2,"title":"Download &amp; Install a Linux Distribution","text":"<p>Steps:</p> <ul> <li>Download</li> <li>To install, run `Add-AppxPackage .\\app_name.appx`</li> <li>Double-click on the installed app, which will exists within the applications' menu, to activate it.  You will be asked to set up credentials.</li> </ul> <p></p>","path":["Machines","Linux &amp; Windows Subsystem for Linux (WSL)"],"tags":[]},{"location":"sections/machines-wsl/#commands","level":2,"title":"Commands","text":"<p>Basic Commands</p> <p> </p> <p> </p> <p> </p> <p> </p>","path":["Machines","Linux &amp; Windows Subsystem for Linux (WSL)"],"tags":[]}]}